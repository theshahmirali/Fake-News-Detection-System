{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Extraction Script\n",
    "**Applying feature extraction techniques to the dataset**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1. Change the directory to dataset directory**\n",
    "\n",
    "**2. While running test script comment out the line below**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cd \"D:\\University\\FIT3162\\Project\\Fake-News-Detection\\Feature Extraction\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sentiment_vader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sentiment Analysis Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeatureExtraction:\n",
    "    \"\"\"\n",
    "    This class is used to build a pipeline for sentiment feature extraction using Vader\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        self.post_file = \"cleaned_df.csv\"\n",
    "        self.comment_file = \"cleaned_comments.csv\"\n",
    "        self.post_df = None\n",
    "        self.comment_df = None\n",
    "        self.comment_scores = {}\n",
    "    \n",
    "    def read_datasets(self):\n",
    "        self.post_df = pd.read_csv(self.post_file, index_col = 0)\n",
    "        self.comment_df = pd.read_csv(self.comment_file, index_col=0)\n",
    "    \n",
    "    def print_statistics(self):\n",
    "        print(\"Number of Posts\", len(self.post_df))\n",
    "        print(\"Number of Comments\", len(self.comment_df))\n",
    "        print(\"Number of Fake Posts\", len(self.post_df.loc[self.post_df['2_way_label'] == 0]))\n",
    "        print(\"Number of True Posts\", len(self.post_df.loc[self.post_df['2_way_label'] == 1]))\n",
    "        \n",
    "    def get_sample_posts(self, sample_size):\n",
    "        self.post_df = self.post_df.sample(sample_size, random_state = 123).reset_index(drop=True)\n",
    "        \n",
    "    def filter_comments(self):\n",
    "        ids = self.post_df.id.unique()\n",
    "        print(ids)\n",
    "        self.comment_df = self.comment_df[self.comment_df['submission_id'].isin(ids)]\n",
    "        self.comment_df = self.comment_df.reset_index(drop=True)\n",
    "        \n",
    "    def build_comment_score(self):\n",
    "        #creating hashtables with post id as key\n",
    "        for ind in self.post_df.index:\n",
    "            # hastable for score of comments\n",
    "            self.comment_scores[self.post_df['id'][ind]] = [0, 0]\n",
    "        sentiment_vader.build_comment_dictionary(self.comment_df, self.comment_scores)\n",
    "        \n",
    "    def cmnt_sentiment_column(self):\n",
    "        \"\"\"\n",
    "        Add the comment sentiment Column to Post dataset\n",
    "        \"\"\"\n",
    "        temp = list(self.comment_scores.values())\n",
    "        score = [x[0]/x[1] if x[1] > 0 else x[1] for x in temp]\n",
    "        num_comments = [x[1] for x in temp]\n",
    "        \n",
    "        self.post_df[\"num_comments\"] = num_comments\n",
    "        self.post_df[\"comment_sentiment\"] = score\n",
    "            \n",
    "    def post_sentiment_column(self):\n",
    "        self.post_df['post_sentiment'] = self.post_df.apply(lambda x: sentiment_vader.post_sentiment(x['title']), axis=1)\n",
    "        \n",
    "    def build_pipeline(self):\n",
    "        print(\"Step 1: Reading Dataset\")\n",
    "        self.read_datasets()\n",
    "        print(\"Step 2: Filter Posts\")\n",
    "        self.get_sample_posts(100)\n",
    "        print(\"Step 3: Filter Comments\")\n",
    "        self.filter_comments()\n",
    "        print(\"Step 4: Building Comment Score Dictionary\")\n",
    "        self.build_comment_score()\n",
    "        print(\"Step 6: Add Comment Score Column\")\n",
    "        self.cmnt_sentiment_column()\n",
    "        print(\"Step 7: Add Post Score Column\")\n",
    "        self.post_sentiment_column()\n",
    "        print(\"---DONE---\")\n",
    "        \n",
    "    def get_post_dataset(self):\n",
    "        return self.post_df\n",
    "    \n",
    "    def get_comment_dataset(self):\n",
    "        return self.comment_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 1: Reading Dataset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\saadu\\Anaconda3\\lib\\site-packages\\numpy\\lib\\arraysetops.py:569: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  mask |= (ar1 == a)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 2: Filter Posts\n",
      "Step 3: Filter Comments\n",
      "['6hrnqx' 'cig6ey' '630i9h' '840mn2' '4le28i' '2yku3b' '3ocz34' 'cnajfh'\n",
      " 'cbm4y8' '4oqpzv' '70tkf7' '3wbzo9' '65juyw' '7dxccq' '5ge1me' '4y6m0o'\n",
      " 'c9rk7m' '85z99b' '4paruc' '5cwwuw' '7l563u' '5p67pp' '5q7v6g' 'bx5bbs'\n",
      " '5xrtgg' '41v58n' '297d63' '3s98kk' '29st2l' '921ryw' '3c6dkl' 'w1cfz'\n",
      " '3htxqw' '8p8s3e' '18vljl' '3h7dlm' '3huyja' '4q4276' '66v7v7' '7rvsr0'\n",
      " '4jl3yl' 'bblpec' '6qvqbo' '4udo8c' '8jtfs4' '3xb374' '1d4qdd' 'd893e4'\n",
      " 'bn8t1a' '35m737' '4zubf6' '7lq6pw' '7gfr6d' '7epany' 'cggani' '7iz8jp'\n",
      " 'bamwfj' '408s8q' '8dlojy' '8ivr3u' '6fkl11' 'd9eb04' '21xeto' '4hv4jb'\n",
      " '5403c5' '4gsb5r' '9k196i' 'cokjrv' '8nyl4o' 'd56bd9' '823m2s' '45m0ii'\n",
      " '7d8wow' 'cevntw' '7ku5k9' '4zxlxa' '8vzm80' '40yfnz' '8nd8h4' '3h3s73'\n",
      " '7ngtpk' 'b114d8' '97d5qi' '58xrsk' '2rz1qq' '5jt04w' '8fk57t' 'b8io9z'\n",
      " '1fppox' '9946l8' '6pbisc' '52jn05' '7kkrzj' '74sgl8' '81w863' '5srm3t'\n",
      " '34i2hx' '3d1fpi' '4is7wk' '61uor4']\n",
      "Step 4: Building Comment Score Dictionary\n",
      "Step 6: Add Comment Score Column\n",
      "Step 7: Add Post Score Column\n",
      "---DONE---\n"
     ]
    }
   ],
   "source": [
    "# Create a pipeline object\n",
    "feature_extraction = FeatureExtraction()\n",
    "# Read the datasets\n",
    "feature_extraction.build_pipeline()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Posts 10000\n",
      "Number of Comments 820028\n",
      "Number of Fake Posts 5194\n",
      "Number of True Posts 4806\n"
     ]
    }
   ],
   "source": [
    "# Print Statistics\n",
    "feature_extraction.print_statistics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "post_df = feature_extraction.get_post_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>clean_title</th>\n",
       "      <th>created_utc</th>\n",
       "      <th>domain</th>\n",
       "      <th>id</th>\n",
       "      <th>num_comments</th>\n",
       "      <th>score</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>title</th>\n",
       "      <th>upvote_ratio</th>\n",
       "      <th>2_way_label</th>\n",
       "      <th>comment_sentiment</th>\n",
       "      <th>post_sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>can i still cash in my brain needs to rest</td>\n",
       "      <td>2017-06-17 12:58:22</td>\n",
       "      <td>self.SubredditSimulator</td>\n",
       "      <td>6hrnqx</td>\n",
       "      <td>20</td>\n",
       "      <td>17</td>\n",
       "      <td>subredditsimulator</td>\n",
       "      <td>Can I still cash in my brain needs to rest</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.034000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>how did the wheat say to its son photoshop</td>\n",
       "      <td>2019-07-27 18:58:22</td>\n",
       "      <td>self.SubredditSimulator</td>\n",
       "      <td>cig6ey</td>\n",
       "      <td>20</td>\n",
       "      <td>3</td>\n",
       "      <td>subredditsimulator</td>\n",
       "      <td>How did the wheat say to its son Photoshop?</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.196715</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  clean_title          created_utc  \\\n",
       "0  can i still cash in my brain needs to rest  2017-06-17 12:58:22   \n",
       "1  how did the wheat say to its son photoshop  2019-07-27 18:58:22   \n",
       "\n",
       "                    domain      id  num_comments  score           subreddit  \\\n",
       "0  self.SubredditSimulator  6hrnqx            20     17  subredditsimulator   \n",
       "1  self.SubredditSimulator  cig6ey            20      3  subredditsimulator   \n",
       "\n",
       "                                         title  upvote_ratio  2_way_label  \\\n",
       "0   Can I still cash in my brain needs to rest           0.9            0   \n",
       "1  How did the wheat say to its son Photoshop?           1.0            0   \n",
       "\n",
       "   comment_sentiment  post_sentiment  \n",
       "0          -0.034000             0.0  \n",
       "1           0.196715             0.0  "
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "post_df.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Domain Rank Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# https://www.kaggle.com/cheedcheed/top1m\n",
    "# https://github.com/mozilla/cipherscan/tree/master/top1m\n",
    "import re\n",
    "from urllib.parse import urlparse\n",
    "import os\n",
    "import zipfile\n",
    "import pickle \n",
    "\n",
    "class Alexa:\n",
    "    '''\n",
    "    this class provides access to the Alexa ranking of URLs\n",
    "    usage: create a new instance of this class (ranker = Alexa()) and use the get_rank method\n",
    "    '''\n",
    "    __domain_list = []\n",
    "    \n",
    "    def __init__(self):\n",
    "        try:\n",
    "            # read the alexa ranking\n",
    "            f_csv = open('top-1m.csv/top-1m.csv')\n",
    "            csv_data = f_csv.read()\n",
    "            f_csv.close()\n",
    "            lines = csv_data.split(\"\\n\")\n",
    "            for line in lines:\n",
    "                try:\n",
    "                    url = line.split(\",\")[1]\n",
    "                    url = re.sub('^www\\.', '', url)\n",
    "                    self.__domain_list.append(url)\n",
    "                except:\n",
    "                    continue\n",
    "        except:\n",
    "            raise\n",
    "        \n",
    "    def get_rank(self, url):\n",
    "        ''' getrank returns the alexa rank of the domain of the given URL, or -1 if it is over 1M'''\n",
    "        parsed_url = urlparse(url)\n",
    "        if parsed_url.scheme == '':\n",
    "            return self.get_rank('http://'+url)\n",
    "        domain = parsed_url.netloc\n",
    "        domain = re.sub('^www\\.', '', domain)\n",
    "        if domain in self.__domain_list:\n",
    "            return self.__domain_list.index(domain)+1   \n",
    "        return 1000001\n",
    "    \n",
    "    def save_list_pickle(self):\n",
    "        filename = \"rank_list.pkl\"  \n",
    "        with open(filename, 'wb') as file:  \n",
    "            pickle.dump(self.__domain_list, file)\n",
    "        file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "alexa = Alexa()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "alexa.save_list_pickle()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "135"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alexa.get_rank('www.cnn.com')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def add_domain_rank(df):\n",
    "    alexa = Alexa()\n",
    "    df['domain_rank'] = df.apply(lambda x: alexa.get_rank(x['domain']), axis=1)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added Domain Rank Column\n"
     ]
    }
   ],
   "source": [
    "post_df = add_domain_rank(post_df)\n",
    "print(\"Added Domain Rank Column\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Sample Post DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>clean_title</th>\n",
       "      <th>created_utc</th>\n",
       "      <th>domain</th>\n",
       "      <th>id</th>\n",
       "      <th>num_comments</th>\n",
       "      <th>score</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>title</th>\n",
       "      <th>upvote_ratio</th>\n",
       "      <th>2_way_label</th>\n",
       "      <th>comment_sentiment</th>\n",
       "      <th>post_sentiment</th>\n",
       "      <th>domain_rank</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>can i still cash in my brain needs to rest</td>\n",
       "      <td>2017-06-17 12:58:22</td>\n",
       "      <td>self.SubredditSimulator</td>\n",
       "      <td>6hrnqx</td>\n",
       "      <td>20</td>\n",
       "      <td>17</td>\n",
       "      <td>subredditsimulator</td>\n",
       "      <td>Can I still cash in my brain needs to rest</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.034000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1000001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>how did the wheat say to its son photoshop</td>\n",
       "      <td>2019-07-27 18:58:22</td>\n",
       "      <td>self.SubredditSimulator</td>\n",
       "      <td>cig6ey</td>\n",
       "      <td>20</td>\n",
       "      <td>3</td>\n",
       "      <td>subredditsimulator</td>\n",
       "      <td>How did the wheat say to its son Photoshop?</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.196715</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1000001</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  clean_title          created_utc  \\\n",
       "0  can i still cash in my brain needs to rest  2017-06-17 12:58:22   \n",
       "1  how did the wheat say to its son photoshop  2019-07-27 18:58:22   \n",
       "\n",
       "                    domain      id  num_comments  score           subreddit  \\\n",
       "0  self.SubredditSimulator  6hrnqx            20     17  subredditsimulator   \n",
       "1  self.SubredditSimulator  cig6ey            20      3  subredditsimulator   \n",
       "\n",
       "                                         title  upvote_ratio  2_way_label  \\\n",
       "0   Can I still cash in my brain needs to rest           0.9            0   \n",
       "1  How did the wheat say to its son Photoshop?           1.0            0   \n",
       "\n",
       "   comment_sentiment  post_sentiment  domain_rank  \n",
       "0          -0.034000             0.0      1000001  \n",
       "1           0.196715             0.0      1000001  "
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "post_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Save Final Dataset\n",
    "post_df.to_csv('dataset.csv', encoding='utf-8-sig')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
