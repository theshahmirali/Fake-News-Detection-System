{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test for Feature Extraction Script\n",
    "**Applying tests on feature extraction functions**\n",
    "\n",
    "**Moving to the current directory of the script**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:\\University\\FIT3162\\Project\\Fake-News-Detection\\Feature Extraction\n"
     ]
    }
   ],
   "source": [
    "cd \"D:\\University\\FIT3162\\Project\\Fake-News-Detection\\Feature Extraction\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**This class of feature extraction bought here to avoid importing each time**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class FeatureExtraction:\n",
    "    \"\"\"\n",
    "    This class is used to build a pipeline for sentiment feature extraction using Vader\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        self.post_file = \"cleaned_df.csv\"\n",
    "        self.comment_file = \"cleaned_comments.csv\"\n",
    "        self.post_df = None\n",
    "        self.comment_df = None\n",
    "        self.comment_scores = {}\n",
    "    \n",
    "    def read_datasets(self):\n",
    "        self.post_df = pd.read_csv(self.post_file, index_col = 0, encoding = \"ISO-8859-1\")\n",
    "        self.comment_df = pd.read_csv(self.comment_file, index_col=0)\n",
    "    \n",
    "    def print_statistics(self):\n",
    "        print(\"Number of Posts\", len(self.post_df))\n",
    "        print(\"Number of Comments\", len(self.comment_df))\n",
    "        print(\"Number of Fake Posts\", len(self.post_df.loc[self.post_df['2_way_label'] == 0]))\n",
    "        print(\"Number of True Posts\", len(self.post_df.loc[self.post_df['2_way_label'] == 1]))\n",
    "        \n",
    "    def get_sample_posts(self, sample_size):\n",
    "        self.post_df = self.post_df.sample(sample_size, random_state = 123).reset_index(drop=True)\n",
    "        \n",
    "    def filter_comments(self):\n",
    "        ids = self.post_df.id.unique()\n",
    "        print(ids)\n",
    "        self.comment_df = self.comment_df[self.comment_df['submission_id'].isin(ids)]\n",
    "        self.comment_df = self.comment_df.reset_index(drop=True)\n",
    "        \n",
    "    def build_comment_score(self):\n",
    "        #creating hashtables with post id as key\n",
    "        for ind in self.post_df.index:\n",
    "            # hastable for score of comments\n",
    "            self.comment_scores[self.post_df['id'][ind]] = [0, 0]\n",
    "        sentiment_vader.build_comment_dictionary(self.comment_df, self.comment_scores)\n",
    "        \n",
    "    def cmnt_sentiment_column(self):\n",
    "        \"\"\"\n",
    "        Add the comment sentiment Column to Post dataset\n",
    "        \"\"\"\n",
    "        temp = list(self.comment_scores.values())\n",
    "        score = [x[0]/x[1] if x[1] > 0 else x[1] for x in temp]\n",
    "        num_comments = [x[1] for x in temp]\n",
    "        \n",
    "        self.post_df[\"num_comments\"] = num_comments\n",
    "        self.post_df[\"comment_sentiment\"] = score\n",
    "            \n",
    "    def post_sentiment_column(self):\n",
    "        self.post_df['post_sentiment'] = self.post_df.apply(lambda x: sentiment_vader.post_sentiment(x['title']), axis=1)\n",
    "        \n",
    "    def build_pipeline(self):\n",
    "        print(\"Step 1: Reading Dataset\")\n",
    "        self.read_datasets()\n",
    "        print(\"Step 2: Filter Posts\")\n",
    "        self.get_sample_posts(6)\n",
    "        print(\"Step 3: Filter Comments\")\n",
    "        self.filter_comments()\n",
    "        print(\"Step 4: Building Comment Score Dictionary\")\n",
    "        self.build_comment_score()\n",
    "        print(\"Step 6: Add Comment Score Column\")\n",
    "        self.cmnt_sentiment_column()\n",
    "        print(\"Step 7: Add Post Score Column\")\n",
    "        self.post_sentiment_column()\n",
    "        print(\"---DONE---\")\n",
    "        \n",
    "    def get_post_dataset(self):\n",
    "        return self.post_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import unittest\n",
    "import pytest\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import import_ipynb\n",
    "import sentiment_vader\n",
    "from pandas.testing import assert_frame_equal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\saadu\\Anaconda3\\lib\\site-packages\\numpy\\lib\\arraysetops.py:569: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  mask |= (ar1 == a)\n"
     ]
    }
   ],
   "source": [
    "feature = FeatureExtraction()\n",
    "feature.read_datasets()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class TestFeatureExtraction(unittest.TestCase):\n",
    "    \n",
    "    def test_read_datasets(self):\n",
    "        feature = FeatureExtraction()\n",
    "\n",
    "        expected_posts = pd.read_csv('cleaned_df.csv', encoding = \"ISO-8859-1\")\n",
    "        expected_comments = pd.read_csv('cleaned_comments.csv')\n",
    "\n",
    "        feature.read_datasets()\n",
    "\n",
    "        result_posts = feature.post_df\n",
    "        result_comments = feature.comment_df\n",
    "        \n",
    "\n",
    "        expected_rows_posts = len(expected_posts.index)\n",
    "        result_rows_posts = len(result_posts.index)\n",
    "        \n",
    "        expected_rows_comments = len(expected_comments.index)\n",
    "        result_rows_comments = len(result_comments.index)\n",
    "  \n",
    "        self.assertEqual(expected_rows_posts, result_rows_posts)\n",
    "        self.assertEqual(expected_rows_comments, result_rows_comments)\n",
    "        \n",
    "    def test_cmnt_sentiment_column(self):\n",
    "        feature.filter_comments()\n",
    "        feature.build_comment_score()\n",
    "        feature.cmnt_sentiment_column()\n",
    "        \n",
    "        feature.get_post_dataset().to_csv('df1.csv')\n",
    "        result = pd.read_csv('df1.csv', encoding = \"ISO-8859-1\")\n",
    "        assert abs(result.iloc[0]['comment_sentiment'] - 0.088095896) <= 0.001,\n",
    "        'Perform Comment sentiment test failed'\n",
    "\n",
    "        \n",
    "        \n",
    "    def test_post_sentiment_column(self):\n",
    "        \n",
    "        feature.post_sentiment_column()\n",
    "        \n",
    "        result = feature.get_post_dataset().to_csv('df2.csv')\n",
    "        result = pd.read_csv('df2.csv', encoding = \"ISO-8859-1\")\n",
    "        assert result.iloc[0]['post_sentiment'] == 0\n",
    "        assert abs(result.iloc[1]['post_sentiment'] - 0.7906) <= 0.001, \n",
    "        'Perform Post Sentiment test failed'\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['86byl8' '796d3z' '6ttusb' '75yogr' 'd0x9x3' '54zzy4' 'atmab5' '8zhu6j'\n",
      " 'ben0cn' '7erxmm' '9b2qiv' '52q9bj' '6uo9g3' '54jf92' '1egffl' 'd5uvv8'\n",
      " '6bvpes' '6qnyqt' 'c62msf' '6kxdds' 'cc8eid' 'btlq8x' '42l6vy' '4ooe12'\n",
      " '6rljfc' '96hi5z' '7m9jvd' '5ulz1z' '593joh' '745qsl']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "..C:\\Users\\saadu\\Anaconda3\\lib\\site-packages\\numpy\\lib\\arraysetops.py:569: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  mask |= (ar1 == a)\n",
      ".\n",
      "----------------------------------------------------------------------\n",
      "Ran 3 tests in 31.701s\n",
      "\n",
      "OK\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    unittest.main(argv=['first-arg-is-ignored for jupyter'], exit=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
