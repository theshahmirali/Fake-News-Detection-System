{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Descriptive Analysis Script\n",
    "**Applying techniques to learn about the datasets**\n",
    "\n",
    "**Importing libraries**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime as dt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1. Change the directory to dataset directory**\n",
    "\n",
    "**2. While running test script comment out the line below**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cd \"D:\\University\\FIT3162\\FAKEDDIT\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perform_statistics(df, clean=True):\n",
    "    \"\"\"\n",
    "    Clean (True) Dataset Refers to cleaned_df.csv dataset that has been processed\n",
    "    (False) refers to the raw dataset which is unprocessed.\n",
    "    Apply function to read the post dataset and analyze them\n",
    "    param: dataframe to be analyzed (Clean and Uncleaned)\n",
    "    return: decriptive analysis on the dataset. An output file that is used for the test cases\n",
    "    \"\"\"\n",
    "    total = len(df)\n",
    "    fake_articles = len(df.loc[df['2_way_label'] == 0])\n",
    "    true_articles = len(df.loc[df['2_way_label'] == 1])\n",
    "    num_of_subreddits = df['subreddit'].nunique()\n",
    "    num_of_domains = df['domain'].nunique()\n",
    "    mean_comments = df['num_comments'].mean()\n",
    "    mean_title_len = df['title'].replace(np.nan, '').str.split().apply(len).mean()\n",
    "    if clean:\n",
    "        df['created_utc'] = pd.to_datetime(df['created_utc'])\n",
    "        min_date = min(df['created_utc'])\n",
    "        max_date = max(df['created_utc'])\n",
    "    else:\n",
    "        min_date = dt.datetime.fromtimestamp(min(df['created_utc']))\n",
    "        max_date = dt.datetime.fromtimestamp(max(df['created_utc']))\n",
    "        \n",
    "    \n",
    "\n",
    "    print(\"-\" * 30)\n",
    "    print(\"Total Samples:\", total)\n",
    "    print(\"-\" * 30)\n",
    "    print(\"Fake Samples:\", fake_articles)\n",
    "    print(\"-\" * 30)\n",
    "    print(\"True Samples:\", true_articles)\n",
    "    print(\"-\" * 30)\n",
    "    print(\"Unique Subreddits:\", num_of_subreddits)\n",
    "    print(\"-\" * 30)\n",
    "    print(\"Unique Domains:\", num_of_domains)\n",
    "    print(\"-\" * 30)\n",
    "    print(\"Mean No of Comments:\", mean_comments)\n",
    "    print(\"-\" * 30)\n",
    "    print(\"Mean Words in title:\", mean_title_len)\n",
    "    print(\"-\" * 30)\n",
    "    print(\"Min Creation Date:\", min_date)\n",
    "    print(\"-\" * 30)\n",
    "    print(\"Max Creation Date:\", max_date)\n",
    "    print(\"-\" * 30)\n",
    "    \n",
    "    new_df = pd.DataFrame(columns=['total','fake_articles','true_articles','num_subreddit','num_domain','mean_comment','mean_title','min_date','max_date'])\n",
    "\n",
    "    # output used for test cases\n",
    "    new_df.to_csv(r'D:\\University\\FIT3162\\Project\\Fake-News-Detection\\Descriptive Analysis\\post_stats_output.csv',index=False)\n",
    "    \n",
    "    file = open(r'D:\\University\\FIT3162\\Project\\Fake-News-Detection\\Descriptive Analysis\\post_stats_output.csv', 'a')\n",
    "    file.write('{}, {}, {}, {}, {}, {}, {}, {}, {}\\n'.format(total, fake_articles, true_articles, num_of_subreddits, num_of_domains,mean_comments,mean_title_len,min_date,max_date))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_comment_stats(df):\n",
    "     \"\"\"\n",
    "    Apply function to read the comment dataset and analyze them\n",
    "    param: dataframe to be analyzed\n",
    "    return: decriptive analysis on the dataset. An output file that is used for the test cases\n",
    "    \"\"\"\n",
    "    total = len(df)\n",
    "    unique_posts = df['submission_id'].nunique()\n",
    "    print(\"-\" * 30)\n",
    "    print(\"Total Comments:\", total)\n",
    "    print(\"-\" * 30)\n",
    "    print(\"Unique Posts with comments:\", unique_posts)\n",
    "    print(\"-\" * 30)\n",
    "    \n",
    "    new_df = pd.DataFrame(columns=['total','unique_posts'])\n",
    "\n",
    "    # output used for test cases\n",
    "    new_df.to_csv(r'D:\\University\\FIT3162\\Project\\Fake-News-Detection\\Descriptive Analysis\\post_comments_stats_output.csv',index=False)\n",
    "    \n",
    "    file = open(r'D:\\University\\FIT3162\\Project\\Fake-News-Detection\\Descriptive Analysis\\post_comments_stats_output.csv', 'a')\n",
    "    file.write('{}, {}\\n'.format(total, unique_posts))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Calling the analysis functions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Descriptive Analysis\n",
      "------------------------------\n",
      "Total Comments: 4428085\n",
      "------------------------------\n",
      "Unique Posts with comments: 53265\n",
      "------------------------------\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    print(\"Descriptive Analysis\")\n",
    "    post_df = pd.read_csv(\"cleaned_df.csv\")\n",
    "    perform_statistics(post_df)\n",
    "    comment_df = pd.read_csv(\"cleaned_comments.csv\")\n",
    "    check_comment_stats(comment_df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
